<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="ja" lang="ja">
<head>
<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8" />
<title>Publication --- Tomoki Koriyama's website</title>
<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>

<!-- メイン -->

<div id="main">


<!-- ヘッダー -->

<div id="header">
 
<!-- <h1>メインキーワード - などページの１行・紹介文を入れてください</h1> -->

<table border="0" cellpadding="0" cellspacing="0" width="900">
  <tr>
    <td><div id="table-left"><h2>
      <!-- <a href="index.html">Tomoki Koriyama's website</a> -->
      <a href="index-j.html">Tomoki Koriyama's website</a>
    </h2></div></td>
    <td><div id="table-right">
      <a href="publication-j.html">[日本語]</a>
      <a href="publication-e.html">[English]</a>
    </div></td>
  </tr>
</table>

</div>


<div id="header-menu">
   <ul>
    <li><a href="index-j.html">HOME</a></li>
    <li><a href="publication-j.html">研究業績</a></li>
    <li><a href="profile-j.html">プロフィール</a></li>
   </ul>
</div>


<!-- ヘッダー終わり -->


<!-- コンテンツ -->

<!-- メインコンテンツ -->

<div id="container">
  <div id="contents">

<h1>研究業績</h1>

<!-- <p><a href="http://t2r2.star.titech.ac.jp/cgi-bin/researcherpublicationlist.cgi?lv=en&q_researcher_content_number=CTT100509278">T2R2</a></p>
 -->
<a name="journal"></a>
<h2>論文</h2>
<div class="box_scrollbar">

<ol class="publication">

    <li>Shinnosuke Takamichi, Ryosuke Sonobe, Kentaro Mitsui, Yuki Saito, <em class="author">Tomoki Koriyama</em>, Naoko Tanji, Hiroshi Saruwatari,<br />
    <em class="title">``JSUT and JVS: free Japanese voice corpora for accelerating speech synthesis research,''</em></br>
    Acoustical Science and Technology.(2020) (In press)</li>

    <li>Hiroki Tamaru, Yuki Saito, Shinnosuke Takamichi, <em class="author">Tomoki Koriyama</em>, Hiroshi Saruwatari,<br />
    <em class="title">``Generative moment matching network-based neural double-tracking for synthesized and natural singing voices,''</em></br>
    IEICE Transactions on Information and Systems, vol.E103.D, pp.639-647.(2020)
    <a href="https://doi.org/10.1587/transinf.2019EDP7228">[official]</a></li>

    <li><em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``Statistical Parametric Speech Synthesis Using Deep Gaussian Processes,''</em></br>
    IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol.27, no.5, pp.948-959. (May 2019)
    <a href="https://doi.org/10.1109/TASLP.2019.2905167">[official]</a>
    <a href="https://hyama5.github.io/DeepGPTTSSamples">[demo]</a>
    <a href="https://www.slideshare.net/tomokikoriyama/a-training-method-using-dnnguided-layerwise-pretraining-for-deep-gaussian-processes">[slide]</a></li>

    <li>Decha Moungsri, <em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``GPR-based Thai speech synthesis using multi-level duration prediction,''</em></br>
    Speech Communication, vol.99, pp.114-123. (May 2018)
    <a href="https://doi.org/10.1016/j.specom.2018.03.005">[official]</a></li>


    <li>長濱大樹, 能勢 隆, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``クロスリンガル音声合成のための共有決定木コンテクストクラスタリングを用いた話者適応,''</em></br>
    電子情報通信学会論文誌D, vol.J100-D, no.3, pp.385-393. (Mar. 2017)
    <a href="https://search.ieice.org/bin/summary.php?id=j100-d_3_385">[official]</a></li>

    <li>Takashi Nose, Misa Kanemoto, <em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``HMM-based expressive singing voice synthesis with singing style control and robust pitch modeling,''</em></br>
    Computer Speech &amp; Language, vol.34, no.1, pp.308-322. (Nov. 2015)
    <a href="http://dx.doi.org/10.1016/j.csl.2015.04.001">[official]</a></li>

    <li><em class="author">Tomoki Koriyama</em>, Takashi Nose, Takao Kobayashi,<br />
    <em class="title">``Statistical Parametric Speech Synthesis Based on Gaussian Process Regression,''</em></br>
    IEEE Journal of Selected Topics in Signal Processing, vol.8, no.2, pp.173-183. (Apr. 2014)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100668101/ATD100000413/">[PDF]</a>
    <a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6609068">[official]</a>
    <a href="http://www.kbys.ip.titech.ac.jp/demo/gpss/koriyama/">[demo]</a></li>

    <li>Yu Maeno, Takashi Nose, Takao Kobayashi, <em class="author">Tomoki Koriyama</em>, Yusuke Ijima, Hideharu Nakajima, Hideyuki Mizuno, Osamu Yoshioka,<br />
    <em class="title">``Prosodic Variation Enhancement Using Unsupervised Context Labeling for HMM-based Expressive Speech Synthesis,''</em></br>
    Speech Communication, vol.57, no.3, pp.144–154. (Feb. 2014)
    <a href="http://www.sciencedirect.com/science/article/pii/S0167639313001350">[official]</a></li>

    <li><em class="author">郡山知樹</em>, 能勢 隆, 小林隆夫,<br />
    <em class="title">``HMMに基づく対話音声合成における多様な韻律生成のためのコンテクストの拡張,''</em></br>
    電子情報通信学会論文誌D, vol.J95-D, no.3, pp.597-607. (Mar. 2012)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100634462/ATD100000413/">[PDF]</a>
    <a href="http://search.ieice.org/bin/summary.php?id=j95-d_3_597">[official]</a></li>

</ol>
</div>

<a name="international_conference"></a>
<h2>国際会議論文</h2>
<div class="box_scrollbar">
<ol class="publication">
    <li>Yuki Yamashita, <em class="author">Tomoki Koriyama</em>, Yuki Saito, Shinnosuke Takamichi, Yusuke Ijima, Ryo Masumura, Hiroshi Saruwatari,<br />
    <em class="title">``DNN-based Speech Synthesis Using Abundant Tags of Spontaneous Speech Corpus,''</em></br>
    Proc. 12th edition of the Language Resources and Evaluation Conference (LREC 2020), pp.xxx-xxx. (May 2020)</li>

    <li><em class="author">Tomoki Koriyama</em>, Hiroshi Saruwatari,<br />
    <em class="title">``Utterance-level Sequential Modeling For Deep Gaussian Process Based Speech Synthesis Using Simple Recurrent Unit,''</em></br>
    Proc. 45th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2020), pp.xxx-xxx. (May 2020) (In press)
    <a href="https://hyama5.github.io/demo_SRU_DGP_TTS">[demo]</a></li>

    <li><em class="author">Tomoki Koriyama</em>, Shinnosuke Takamichi, Takao Kobayashi,<br />
    <em class="title">``Sparse Approximation of Gram Matrices for GMMN-based Speech Synthesis,''</em></br>
    Proc. The 10th ISCA Speech Synthesis Workshop (SSW10), pp.149-154. (Sept. 2019)
    <a href="http://dx.doi.org/10.21437/SSW.2019-27">[official]</a>
    <a href="https://www.slideshare.net/tomokikoriyama/sparse-approximation-of-gram-matrices-for-gmmnbased-speech-synthesis">[slide]</a></li>

    <li><em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``Semi-Supervised Prosody Modeling Using Deep Gaussian Process Latent Variable Model,''</em></br>
    Proc. Interspeech 2019, pp.4450-4454. (Sept. 2019)
    <a href="http://dx.doi.org/10.21437/Interspeech.2019-2497">[official]</a>
    <a href="https://www.slideshare.net/tomokikoriyama/semisupervised-prosody-modeling-using-deep-gaussian-process-latent-variable-model">[slide]</a></li>

    <li><em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``A Training Method Using DNN-guided Layerwise Pretraining For Deep Gaussian Processes,''</em></br>
    Proc. 44th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2019), pp.4785-4789. (May 2019)
    <a href="https://ieeexplore.ieee.org/document/8683372">[official]</a>
    <a href="https://github.com/hyama5/deepgp_pretraining">[demo]</a>
    <a href="https://www.slideshare.net/tomokikoriyama/a-training-method-using-dnnguided-layerwise-pretraining-for-deep-gaussian-processes">[slide]</a>
    <a href="https://drive.google.com/file/d/1cOtaEutUVYBQGh38Azr0Vxkrc_SojknJ/view?usp=sharing">[PDF (preprint, copyright©2019 IEEE)]</a></li>

    <li>Hiroki Tamaru, Yuki Saito, Shinnosuke Takamichi, <em class="author">Tomoki Koriyama</em>, Hiroshi Saruwatari,<br />
    <em class="title">``Generative Moment Matching Network-based Random Modulation Post-filter For Dnn-based Singing Voice Synthesis And Neural Double-tracking,''</em></br>
    Proc. 44th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2019), pp.1975-1979. (May 2019)
    <a href="https://ieeexplore.ieee.org/document/8683476">[official]</a></li>

    <li>Decha Moungsri, <em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``Enhanced F0 generation for GPR-based speech synthesis considering syllable-based prosodic features,''</em></br>
    Proc. 2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, PID:47 (4 pages). (Dec. 2017)</li>

    <li>Nattapong Kurpukdee, <em class="author">Tomoki Koriyama</em>, Takao Kobayashi, Sawit Kasuriya, Chai Wutiwiwatchai, Poonlap Lamsrichan,<br />
    <em class="title">``Speech emotion recognition using convolutional long short-term memory neural network and support vector machines,''</em></br>
    Proc. 2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, PID:223 (6 pages). (Dec. 2017)</li>

    <li>Shinnosuke Takamichi, <em class="author">Tomoki Koriyama</em>, Hiroshi Saruwatari,<br />
    <em class="title">``Sampling-Based Speech Parameter Generation Using Moment-Matching Networks,''</em></br>
    Proc. 18th Annual Conference of the International Speech Communication (INTERSPEECH 2017), pp.3961-3965. (Aug. 2017)
    <a href="http://dx.doi.org/10.21437/Interspeech.2017-362">[official]</a></li>

    <li>Decha Moungsri, <em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``Duration Prediction Using Multiple Gaussian Process Experts For GPR-based Speech Synthesis,''</em></br>
    Proc. 42nd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2017), pp.5495-5498. (Mar. 2017)
    <a href="https://doi.org/10.1109/ICASSP.2017.7953207">[official]</a></li>

    <li>Decha Moungsri, <em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``Unsupervised Stress Information Labeling Using Gaussian Process Latent Variable Model for Statistical Speech Synthesis,''</em></br>
    Proc. 17th Annual Conference of the International Speech Communication (INTERSPEECH 2016), pp.1517-1521. (Sept. 2016)
    <a href="http://dx.doi.org/10.21437/Interspeech.2016-273">[official]</a></li>

    <li>Decha Moungsri, <em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``Tone modeling using Gaussian process latent variable model for statistical speech synthesis,''</em></br>
    Proc. Speech Prosody 2016, pp.1014-1018. (May 2016)
    <a href="http://dx.doi.org/10.21437/SpeechProsody.2016-208">[official]</a></li>

    <li><em class="author">Tomoki Koriyama</em>, Syohei Oshio, Takao Kobayashi,<br />
    <em class="title">``A Speaker Adaptation Technique For Gaussian Process Regression Based Speech Synthesis Using Feature Space Transform,''</em></br>
    Proc. 41st IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2016), pp.5610-5614. (Mar. 2016)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100703189/ATD100000413/">[PDF]</a>
    <a href="http://dx.doi.org/10.1109/ICASSP.2016.7472751">[official]</a>
    <a href="http://www.kbys.ip.titech.ac.jp/demo/gpradapt/koriyama/">[demo]</a></li>

    <li>Decha Moungsri, <em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``Duration prediction using multi-level model for GPR-based speech synthesis,''</em></br>
    Proc. 16th Annual Conference of the International Speech Communication (INTERSPEECH 2015), pp.1591-1595. (Sept. 2015)
    <a href="http://www.isca-speech.org/archive/interspeech_2015/i15_1591.html">[official]</a></li>

    <li><em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``A comparison of speech synthesis systems based on GPR, HMM, and DNN with a small amount of training data,''</em></br>
    Proc. 16th Annual Conference of the International Speech Communication (INTERSPEECH 2015), pp.3496-3500. (Sept. 2015)
    <a href="http://www.isca-speech.org/archive/interspeech_2015/i15_3496.html">[official]</a></li>

    <li><em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``Prosody Generation Using Frame-based Gaussian Process Regression and Classification for Statistical Parametric Speech Synthesis,''</em></br>
    Proc. ICASSP 2015, pp.4929-4933. (Apr. 2015)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100686444/ATD100000413/">[PDF]</a>
    <a href="http://dx.doi.org/10.1109/ICASSP.2015.7178908">[official]</a></li>

    <li>Decha Moungsri, <em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``HMM-based Thai speech synthesis using unsupervised stress context labeling,''</em></br>
    Proc. 2014 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, PID:1138. (Dec. 2014)</li>

    <li><em class="author">Tomoki Koriyama</em>, Takashi Nose, Takao Kobayashi,<br />
    <em class="title">``Parametric Speech Synthesis Using Local and Global Sparse Gaussian Processes,''</em></br>
    Proc. The 24th IEEE International Workshop on Machine Learning for Signal Processing. (Sept. 2014)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100677067/ATD100000413/">[PDF]</a>
    <a href="http://dx.doi.org/10.1109/MLSP.2014.6958921">[official]</a></li>

    <li><em class="author">Tomoki Koriyama</em>, Hiroshi Suzuki, Takashi Nose, Takahiro Shinozaki, Takao Kobayashi,<br />
    <em class="title">``Accent Type and Phrase Boundary Estimation Using Acoustic and Language Models for Automatic Prosodic Labeling,''</em></br>
    Proc. INTERSPEECH 2014, pp.2337-2341. (Sept. 2014)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100677068/ATD100000413/">[PDF]</a>
    <a href="http://www.isca-speech.org/archive/interspeech_2014/i14_2337.html">[official]</a></li>

    <li>Daiki Nagahama, Takashi Nose, <em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``Transform mapping using shared decision tree context clustering for HMM-based cross-lingual speech synthesis,''</em></br>
    Proc. INTERSPEECH 2014, pp.770-774. (Sept. 2014)
    <a href="http://www.isca-speech.org/archive/interspeech_2014/i14_0770.html">[official]</a></li>

    <li>Decha Moungsri, <em class="author">Tomoki Koriyama</em>, Takashi Nose, Takao Kobayashi,<br />
    <em class="title">``Tone Modeling Using Stress Information for HMM-Based Thai Speech Synthesis,''</em></br>
    Proc. Speech Prosody 2014, pp.1057-1061. (May 2014)</li>

    <li><em class="author">Tomoki Koriyama</em>, Takashi Nose, Takao Kobayashi,<br />
    <em class="title">``Parametric Speech Synthesis Based on Gaussian Process Regression Using Global Variance and Hyperparameter Optimization,''</em></br>
    Proc. ICASSP 2014, pp.3862-3866. (May 2014)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100668124/ATD100000413/">[PDF]</a></li>

    <li><em class="author">Tomoki Koriyama</em>, Takashi Nose, Takao Kobayashi,<br />
    <em class="title">``Statistical nonparametric speech synthesis using sparse Gaussian processes,''</em></br>
    Proc. INTERSPEECH 2013, pp.1072-1076. (Aug. 2013)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100668125/ATD100000413/">[PDF]</a></li>

    <li>Takashi Nose, Misa Kanemoto, <em class="author">Tomoki Koriyama</em>, Takao Kobayashi,<br />
    <em class="title">``A Style Control Technique for Singing Voice Synthesis Based on Multiple-regression HSMM,''</em></br>
    Proc. INTERSPEECH 2013, pp.378-382. (Aug. 2013)</li>

    <li><em class="author">Tomoki Koriyama</em>, Takashi Nose, Takao Kobayashi,<br />
    <em class="title">``Frame-level Acoustic Modeling Based on Gaussian Process Regression for Statistical Nonparametric Speech Synthesis,''</em></br>
    Proc. ICASSP 2013, pp.8007-8010. (May 2013)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100657345/ATD100000413/">[PDF]</a></li>

    <li>Yu Maeno, Takashi Nose, Takao Kobayashi, <em class="author">Tomoki Koriyama</em>, Yusuke Ijima, Hideharu Nakajima, Hideyuki Mizuno, Osamu Yoshioka,<br />
    <em class="title">``HMM-based Expressive Speech Synthesis Based on Phrase-level F0 Context Labeling,''</em></br>
    Proc. ICASSP 2013, pp.7859-7863. (May 2013)</li>

    <li><em class="author">Tomoki Koriyama</em>, Takashi Nose, Takao Kobayashi,<br />
    <em class="title">``Discontinuous Observation HMM for Prosodic-event-based F0 Generation,''</em></br>
    Proc. INTERSPEECH 2012, pp.462-465. (Sept. 2012)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100644237/ATD100000413/">[PDF]</a></li>

    <li><em class="author">Tomoki Koriyama</em>, Takashi Nose, Takao Kobayashi,<br />
    <em class="title">``An F0 Modeling Technique Based on Prosodic Events for Spontaneous Speech Synthesis,''</em></br>
    Proc. ICASSP 2012, pp.4589-4593. (May 2012)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100636072/ATD100000413/">[PDF]</a></li>

    <li><em class="author">Tomoki Koriyama</em>, Takashi Nose, Takao Kobayashi,<br />
    <em class="title">``On the Use of Extended Context for HMM-based Spontaneous Conversational Speech Synthesis,''</em></br>
    Proc. INTERSPEECH 2011, pp.2657-2660. (Aug. 2011)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100627749/ATD100000413/">[PDF]</a></li>

    <li><em class="author">Tomoki Koriyama</em>, Takashi Nose, Takao Kobayashi,<br />
    <em class="title">``Conversational Spontaneous Speech Synthesis Using Average Voice Model,''</em></br>
    Proc. INTERSPEECH 2010, pp.853-856. (Sept. 2010)</li>
</ol>
</div>

<a name="review"></a>
<h2>招待論文・解説</h2>
<div class="box_scrollbar">
<ol class="publication">
    <li><em class="author">Tomoki Koriyama</em>,<br />
    <em class="title">``An introduction of Gaussian processes and deep Gaussian processes and their applications to speech processing,''</em></br>
    Acoustical Science and Technology, vol.41, no.2, pp.457-464.(2020)
    <a href="https://doi.org/10.1250/ast.41.457">[official]</a></li>

    <li><em class="author">郡山知樹</em>,<br />
    <em class="title">``ガウス過程・深層ガウス過程とそれらの音声情報処理への応用,''</em></br>
    日本音響学会誌, vol.76, no.2, pp.109-116.(2020)</li>
</ol>
</div>

<a name="domestic_conference"></a>
<h2>国内大会</h2>
<div class="box_scrollbar">
<ol class="publication">

    <li><em class="author">郡山知樹</em>, 猿渡洋,<br />
    <em class="title">``深層ガウス過程音声合成における関数の確率微分方程式表現の利用の検討,''</em></br>
    日本音響学会2020年春季研究発表会講演論文集, 2-Q-44, pp.1127-1128. (Mar. 2020)
    <a href="https://drive.google.com/file/d/1zBN7JBiBdrRWM9UB5V_oM6laSfXV5EcD/view?usp=sharing">[PDF]</a></li>

    <li>高道慎之介, 小沼海, 金田卓, 金田隆志, 齋藤佑樹, <em class="author">郡山知樹</em>, 猿渡洋,<br />
    <em class="title">``周波数伸縮に基づく話者匿名化のためのクラウドソーシングに基づくパラメータ最適化,''</em></br>
    日本音響学会2020年春季研究発表会講演論文集, 3-P-31, pp.1159-1162. (Mar. 2020)</li>

    <li>蛭田宜樹, <em class="author">郡山知樹</em>, 太刀岡勇気, 小林隆夫,<br />
    <em class="title">``スタイル適応したDNN音声合成における話者性の検討,''</em></br>
    日本音響学会2020年春季研究発表会講演論文集, 2-Q-34, pp.1103-1104. (Mar. 2020)</li>

    <li>芹川武尊, <em class="author">郡山知樹</em>, 猿渡洋,<br />
    <em class="title">``Attentionに基づく音声変換のためのアラインメント予測モデルの検討,''</em></br>
    日本音響学会2020年春季研究発表会講演論文集, 2-2-2, pp.1077-1078. (Mar. 2020)</li>

    <li>高道慎之介, 齋藤佑樹, 中村友彦, <em class="author">郡山知樹</em>, 猿渡洋,<br />
    <em class="title">``manga2voice:マンガ画像からの音声合成に向けた音声分析,''</em></br>
    日本音響学会2020年春季研究発表会講演論文集, 1-2-15, pp.1065-1068. (Mar. 2020)</li>

    <li>三井健太郎, <em class="author">郡山知樹</em>, 猿渡洋,<br />
    <em class="title">``深層ガウス過程に基づく多話者音声合成,''</em></br>
    日本音響学会2020年春季研究発表会講演論文集, 1-2-2, pp.1043-1044. (Mar. 2020)</li>

    <li><em class="author">郡山知樹</em>, 猿渡洋,<br />
    <em class="title">``深層ガウス過程に基づく音声合成におけるリカレント構造を用いた系列モデリングの検討,''</em></br>
    日本音響学会2019年秋季研究発表会講演論文集, 1-P-25, pp.1025-1026. (Sept. 2019)
    <a href="https://drive.google.com/file/d/1OwCOpx6vY6WDjVd0MV-etupqvwjkmwG-/view?usp=sharing">[PDF]</a>
    <a href="https://www.slideshare.net/tomokikoriyama/ss-212896094">[slide]</a></li>

    <li>田丸浩気, 齋藤佑樹, 高道慎之介, <em class="author">郡山知樹</em>, 猿渡洋,<br />
    <em class="title">``ユーザ歌唱のための generative moment matching network に基づく neural double-tracking,''</em></br>
    日本音響学会2019年秋季研究発表会講演論文集, 1-4-5, pp.935-938. (Sept. 2019)</li>

    <li><em class="author">郡山知樹</em>, 高道慎之介, 小林隆夫,<br />
    <em class="title">``グラム行列のスパース近似を用いた生成的モーメントマッチングネットに基づく音声合成の検討,''</em></br>
    日本音響学確率び分会2019年春季研究発表会講演論文集, 3-10-6, pp.1065-1066. (Mar. 2019)</li>

    <li><em class="author">郡山知樹</em>, 高道慎之介, 小林隆夫,<br />
    <em class="title">``グラム行列のスパース近似を用いた生成的モーメントマッチングネットに基づく音声合成の検討,''</em></br>
    日本音響学会2019年春季研究発表会講演論文集, 3-10-6, pp.1065-1066. (Mar. 2019)
    <a href="https://drive.google.com/open?id=1DoGz9gwB436xpF4OjbxV5FmPXPQHFzQl">[PDF]</a>
    <a href="https://www.slideshare.net/tomokikoriyama/ss-148962780">[slide]</a></li>

    <li>成田昂世, <em class="author">郡山知樹</em>, 小林隆夫, 井島勇祐,<br />
    <em class="title">``対話情報を考慮した韻律生成の検討,''</em></br>
    日本音響学会2019年春季研究発表会講演論文集, 1-P-37, pp.1131-1132. (Mar. 2019)</li>

    <li>蛭田宜樹, <em class="author">郡山知樹</em>, 太刀岡勇気, 小林隆夫,<br />
    <em class="title">``DNN音声合成における少量の学習データを用いたスタイル付与の検討,''</em></br>
    日本音響学会2019年春季研究発表会講演論文集, 1-P-33, pp.1119-1120. (Mar. 2019)</li>

    <li>田丸浩気, 齋藤佑樹, 高道慎之介, <em class="author">郡山知樹</em>, 猿渡洋,<br />
    <em class="title">``Generative moment matching netに基づく歌声のランダム変調ポストフィルタとdouble-trackingへの応用,''</em></br>
    日本音響学会2019年春季研究発表会講演論文集, 2-10-5, pp.1035-1038. (Mar. 2019)</li>

    <li><em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``深層ガウス過程に基づく音声合成のための事前学習の検討,''</em></br>
    日本音響学会2018年秋季研究発表会講演論文集, 1-4-4, pp.1089-1090. (Mar. 2018)
    <a href="https://drive.google.com/open?id=1tItoeS1rG9BwkPO7iNwm8gu5atmkB88P">[PDF]</a>
    <a href="https://www.slideshare.net/tomokikoriyama/ss-114264162">[slide]</a></li>


    <li><em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``GPR音声合成のための深層構造の利用の検討,''</em></br>
    日本音響学会2018年春季研究発表会講演論文集, 3-8-6, pp.1507-1508. (Mar. 2018)
    <a href="https://t2r2.star.titech.ac.jp/rrws/file/CTT100760841/ATD100000413/">[PDF]</a></li>

    <li>前野雄也, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``GPR音声合成における区分線形変換を用いたスタイル適応のためのデータ分割法の検討,''</em></br>
    日本音響学会2018年春季研究発表会講演論文集, 1-Q-36, pp.295-296. (Mar. 2018)</li>

    <li><em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``GPR音声合成のためのフレームコンテキストカーネルに基づく決定木構築の検討,''</em></br>
    日本音響学会2017年秋季研究発表会講演論文集, 1-8-3, pp.177-178. (Sept. 2017)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100753522/ATD100000413/">[PDF]</a>
    <a href="https://www.slideshare.net/tomokikoriyama/gpr-80246175">[slide]</a></li>

    <li><em class="author">郡山知樹</em>, 岡野 祐紀, 小林隆夫,<br />
    <em class="title">``ガウス過程回帰に基づく歌声合成の検討,''</em></br>
    日本音響学会2017年秋季研究発表会講演論文集, 2-Q-24, pp.295-296. (Sept. 2017)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100753523/ATD100000413/">[PDF]</a></li>

    <li>高道慎之介, <em class="author">郡山知樹</em>, 猿渡 洋,<br />
    <em class="title">``Moment-matching networkに基づく一期一会音声合成における発話間ゆらぎの評価,''</em></br>
    日本音響学会2017年秋季研究発表会講演論文集, 1-8-9, pp.195-196. (Sept. 2017)</li>

    <li>高橋亮, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``コンテキストを考慮した音素マッチングに基づく非パラレルデータGMM声質変換,''</em></br>
    日本音響学会2017年春季研究発表会講演論文集, 2-P-37, pp.367-378. (Mar. 2017)</li>

    <li>高道慎之介, <em class="author">郡山知樹</em>, 猿渡 洋,<br />
    <em class="title">``Moment matching networkを用いた音声パラメータのランダム生成の検討,''</em></br>
    日本音響学会2017年春季研究発表会講演論文集, 2-6-9, pp.265-266. (Mar. 2017)</li>

    <li>津野駿幸, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``GPR音声合成に基づいたオーディオブック音声の合成,''</em></br>
    日本音響学会2017年春季研究発表会講演論文集, 1-Q-29, pp.295-296. (Mar. 2017)</li>

    <li>増子理菜, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``アクセント情報自動ラベリングの音声合成品質への影響に関する検討,''</em></br>
    日本音響学会2017年春季研究発表会講演論文集, 1-Q-25, pp.283-284. (Mar. 2017)</li>

    <li>高橋亮, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``非パラレルデータを用いるGMM声質変換の検討,''</em></br>
    日本音響学会2016年秋季研究発表会講演論文集, 3-Q-31, pp.267-268. (Sept. 2016)</li>

    <li>前野雄也, 押尾翔平, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``GPR音声合成における区分線形特徴量変換を用いたスタイル適応の検討,''</em></br>
    日本音響学会2016年秋季研究発表会講演論文集, 2-Q-35, pp.213-214. (Sept. 2016)</li>

    <li>岡元伶洋, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``多様なスタイルによるGPR音声合成の検討,''</em></br>
    日本音響学会2016年春季研究発表会講演論文集, 1-R-49, pp.358-359. (Mar. 2016)</li>

    <li>前野雄也, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``GPR音声合成におけるスタイル適応の検討,''</em></br>
    日本音響学会2016年春季研究発表会講演論文集, 2-2-2, pp.233-234. (Mar. 2016)</li>

    <li><em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``ガウス過程回帰に基づく音声合成システムの評価,''</em></br>
    日本音響学会2015年秋季研究発表会講演論文集, 3-1-3, pp.235-236. (Sept. 2015)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100696875/ATD100000413/">[PDF]</a></li>

    <li>押尾翔平, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``GPR音声合成における話者適応手法の検討,''</em></br>
    日本音響学会2015年秋季研究発表会講演論文集, 2-1-2, pp.219-220. (Sept. 2015)</li>

    <li><em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``ガウス過程回帰に基づく音声合成システムの検討,''</em></br>
    日本音響学会2015年春季研究発表会講演論文集, 2-2-9, pp.269-270. (Mar. 2015)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100686445/ATD100000413/">[PDF]</a></li>

    <li>増子理菜, <em class="author">郡山知樹</em>, 篠崎隆宏, 小林隆夫,<br />
    <em class="title">``言語モデルと音響モデルを用いた自動韻律ラベリングの評価,''</em></br>
    日本音響学会2015年春季研究発表会講演論文集, 1-R-37, pp.361-362. (Mar. 2015)</li>

    <li>岡元伶洋, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``ガウス過程回帰に基づく音声合成のためのコンテキストの検討,''</em></br>
    日本音響学会2015年春季研究発表会講演論文集, 2-Q-31, pp.371-372. (Mar. 2015)</li>

     <li><em class="author">郡山知樹</em>, 能勢 隆, 小林隆夫,<br />
    <em class="title">``ガウス過程回帰に基づくF0パタン生成の検討,''</em></br>
    日本音響学会2014年秋期研究発表会講演論文集, 2-7-8, pp.247-248. (Sept. 2014)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100677070/ATD100000413/">[PDF]</a></li>

    <li><em class="author">郡山知樹</em>, 能勢 隆, 小林隆夫,<br />
    <em class="title">``系列内変動を考慮したガウス過程回帰に基づく音声パラメータ生成,''</em></br>
    日本音響学会2014年春季研究発表会講演論文集, 3-6-15, pp.355-356. (Mar. 2014)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100668127/ATD100000413/">[PDF]</a></li>

    <li>荒生侑介, 能勢 隆, <em class="author">郡山知樹</em>, 篠崎隆宏, 小林隆夫,<br />
    <em class="title">``音声合成のための音韻・韻律コンテキストを考慮した文選択アルゴリズムの評価,''</em></br>
    日本音響学会2014年春季研究発表会講演論文集, 1-R5-13, pp.405-406. (Mar. 2014)</li>

    <li>舘野英樹, 能勢 隆, <em class="author">郡山知樹</em>, 篠崎隆宏, 小林隆夫,<br />
    <em class="title">``HMM音声合成のための音節出現頻度にロバストな音素セットの検討,''</em></br>
    日本音響学会2014年春季研究発表会講演論文集, 1-R5-15, pp.409-410. (Mar. 2014)</li>

    <li>大西浩之, 能勢 隆, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``HMM音声合成における正規化学習を用いたアクセント誤り削減の検討,''</em></br>
    日本音響学会2014年春季研究発表会講演論文集, 1-R5-16, pp.411-412. (Mar. 2014)</li>

    <li>長濱大樹, 能勢 隆, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``共有決定木を利用した話者適応に基づくクロスリンガル音声合成の評価,''</em></br>
    日本音響学会2014年春季研究発表会講演論文集, 1-R5-17, pp.413-414. (Mar. 2014)</li>

    <li>鈴木啓史, <em class="author">郡山知樹</em>, 能勢 隆, 篠崎隆宏, 小林隆夫,<br />
    <em class="title">``音響モデルと言語モデルを利用したアクセント型・アクセント句境界の同時推定,''</em></br>
    日本音響学会2014年春季研究発表会講演論文集, 1-R5-27, pp.441-442. (Mar. 2014)</li>

    <li><em class="author">郡山知樹</em>, 能勢 隆, 小林隆夫,<br />
    <em class="title">``スパース近似と畳み込みカーネルを用いたガウス過程回帰に基づく音声合成,''</em></br>
    日本音響学会2013年秋期研究発表会講演論文集, 2-7-12, pp.311-312. (Sept. 2013)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100668133/ATD100000413/">[PDF]</a></li>

    <li><em class="author">郡山知樹</em>, 能勢 隆, 小林隆夫,<br />
    <em class="title">``音声合成のためのガウス過程回帰を用いたフレームレベル音響モデリングの検討,''</em></br>
    日本音響学会2013年春季研究発表会講演論文集, 1-7-5, pp.271-272. (Mar. 2013)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100652642/ATD100000413/">[PDF]</a></li>

    <li><em class="author">郡山知樹</em>, 能勢 隆, 小林隆夫,<br />
    <em class="title">``観測値の不連続性を考慮したHMMに基づくF0モデル化の検討,''</em></br>
    日本音響学会2012年春季研究発表会講演論文集, 1-11-6, pp.305-306. (Mar. 2012)</li>

    <li><em class="author">郡山知樹</em>, 能勢 隆, 小林隆夫,<br />
    <em class="title">``対話音声合成のためのイントネーションラベルのタイミング予測,''</em></br>
    日本音響学会2011年秋季研究発表会講演論文集, 3-8-2, pp.333-334. (Sept. 2011)</li>

    <li><em class="author">郡山知樹</em>, 能勢 隆, 小林隆夫,<br />
    <em class="title">``二段階モデル適応に基づく対話音声合成の検討,''</em></br>
    日本音響学会2010年秋季研究発表会講演論文集, 2-Q-3, pp.303-304. (Sept. 2010)</li>

    <li><em class="author">郡山知樹</em>, 能勢 隆, 小林隆夫,<br />
    <em class="title">``HMMに基づく対話音声合成のための発話単位の検討,''</em></br>
    日本音響学会2010年春季研究発表会講演論文集, 3-6-19, pp.143-144. (Mar. 2010)</li>

    <li><em class="author">郡山知樹</em>, 能勢 隆, 小林隆夫,<br />
    <em class="title">``HMMに基づく対話音声合成の検討,''</em></br>
    日本音響学会2009年秋季研究発表会講演論文集, 1-2-10, pp.255-256. (Sept. 2009)</li>

    <li><em class="author">郡山知樹</em>, 村上百合, 山口雅浩, 小尾高史, 大山永昭,<br />
    <em class="title">``可視・不可視成分分離とサブサンプリングを用いたマルチスペクトル動画の圧縮符号化方法,''</em></br>
    電子情報通信学会2009年総合大会講演予稿集, D-11-88. (Mar. 2009)</li>

</ol>
</div>

<a name="domestic_workshop"></a>
<h2>国内研究会</h2>
<div class="box_scrollbar">
<ol class="publication">
    <li>山下優樹, <em class="author">郡山知樹</em>, 齋藤佑樹, 高道慎之介, 井島勇祐, 増村亮, 猿渡洋,<br />
    <em class="title">``DNNに基づく話し言葉音声合成における追加コンテキストの効果,''</em></br>
    電子情報通信学会技術研究報告, vol.119, no.441, SP2019-61, pp.65-70. (Mar. 2020)
    <a href="https://www.ieice.org/ken/paper/20200302r1X2/">[official]</a></li>

    <li>三井健太郎, <em class="author">郡山知樹</em>, 猿渡洋,<br />
    <em class="title">``深層ガウス過程とアクセントの潜在変数表現に基づく音声合成の検討,''</em></br>
    電子情報通信学会技術研究報告, vol.119, no.398, SP2019-49, pp.31-36. (Jan. 2020)
    <a href="https://www.ieice.org/ken/paper/20200129t1u9/">[official]</a></li>

    <li>高道慎之介, 三井健太郎, 齋藤佑樹, <em class="author">郡山知樹</em>, 丹治尚子, 猿渡洋,<br />
    <em class="title">``JVS：フリーの日本語多数話者音声コーパス,''</em></br>
    研究報告音声言語情報処理（SLP）, vol.2019-SLP-129, no.7, pp.1-4. (Ocd. 2019)
    <a href="http://id.nii.ac.jp/1001/00199579/">[official]</a></li>

    <li>秋田祐哉, 大町基, 岡本拓磨, 落合翼, 小川厚徳, 神田直之, <em class="author">郡山知樹</em>, 鈴木雅之, 太刀岡勇気, 俵直弘, 増村亮, 渡部晋治,<br />
    <em class="title">``国際会議ICASSP2019報告,''</em></br>
    研究報告音声言語情報処理（SLP）, vol.2019-SLP-128, no.8, pp.1-6. (July 2019)
    <a href="http://id.nii.ac.jp/1001/00197959/">[official]</a></li>

    <li><em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``深層ガウス過程とアクセントの潜在変数表現に基づく音声合成の検討,''</em></br>
    電子情報通信学会技術研究報告, vol.118, no.497, SP2018-91, pp.179-184. (Mar. 2019)
    <a href="https://www.ieice.org/ken/paper/2019031451Lh/">[official]</a><a href="https://www.slideshare.net/tomokikoriyama/ss-148963591">[slide]</a></li>

    <li><em class="author">郡山知樹</em>, 高道慎之介, 小林隆夫,<br />
    <em class="title">``GMMNに基づく音声合成におけるグラム行列のスパース近似の検討,''</em></br>
    研究報告音声言語情報処理（SLP）, vol.2019-SLP-126, no.1, pp.1-6. (Feb. 2019)
    <a href="http://id.nii.ac.jp/1001/00194427/">[official]</a><a href="https://www.slideshare.net/tomokikoriyama/ss-148962780">[slide]</a></li>

    <li><em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``深層ガウス過程とアクセントの潜在変数表現に基づく音声合成の検討,''</em></br>
    電子情報通信学会技術研究報告, vol.118, no.497, SP2018-91, pp.179-184. (Mar. 2019)
    <a href="https://www.ieice.org/ken/paper/2019031451Lh/">[official]</a>
    <a href="https://drive.google.com/open?id=1EQWdorZtKbp6NFaS-RwOKQej1Bxh37Yz">[PDF]</a>
    <a href="https://www.slideshare.net/tomokikoriyama/ss-148963591">[slide]</a></li>

    <li><em class="author">郡山知樹</em>, 高道慎之介, 小林隆夫,<br />
    <em class="title">``GMMNに基づく音声合成におけるグラム行列のスパース近似の検討,''</em></br>
    研究報告音声言語情報処理（SLP）, vol.2019-SLP-126, no.1, pp.1-6. (Feb. 2019)
    <a href="http://id.nii.ac.jp/1001/00194427/">[official]</a>
    <a href="https://drive.google.com/open?id=1TakdbsP3Ti3hBRrSVUYbKoE5rwQUOTWD">[PDF]</a>
    <a href="https://www.slideshare.net/tomokikoriyama/gmmn">[slide]</a></li>

    <li>田丸浩気, 齋藤佑樹, 高道慎之介, <em class="author">郡山知樹</em>, 猿渡洋,<br />
    <em class="title">``モーメントマッチングに基づくDNN合成歌声のランダム変調ポストフィルタとニューラルダブルトラッキングへの応用,''</em></br>
    研究報告音声言語情報処理（SLP）, vol.2018-SLP-125, no.20, pp.1-6. (Dec. 2018)
    <a href="http://id.nii.ac.jp/1001/00192628/">[official]</a></li>

    <li>秋田祐哉, 安藤厚志, 岡本拓磨, 小川厚徳, 神田直之, 倉田岳人, <em class="author">郡山知樹</em>, 篠崎隆宏, 高島遼一, 太刀岡勇気, 藤本雅清, 増村亮,<br />
    <em class="title">``国際会議ICASSP2018参加報告,''</em></br>
    研究報告音声言語情報処理（SLP）, vol.2018-SLP-123, no.2, pp.1-7. (July 2018)
    <a href="http://id.nii.ac.jp/1001/00190527/">[official]</a></li>

    <li><em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``GPR音声合成における深層ガウス過程の利用の検討,''</em></br>
    電子情報通信学会技術研究報告, vol.117, no.517, SP2017-89, pp.27-32. (Mar. 2018)
    <a href="https://t2r2.star.titech.ac.jp/rrws/file/CTT100760843/ATD100000413/">[PDF]</a>
    <a href="http://www.ieice.org/ken/paper/20180319A12x/">[official]</a>
    <a href="https://www.slideshare.net/tomokikoriyama/gpr-91663956">[slide]</a></li>

    <li>高木信二, 倉田岳人, <em class="author">郡山知樹</em>, 塩田さやか, 鈴木雅之, 玉森聡, 俵直弘, 中鹿亘, 福田隆, 増村亮, 森勢将雅, 山岸順一, 山本克彦,<br />
    <em class="title">``国際会議Interspeech2017報告,''</em></br>
    研究報告音声言語情報処理（SLP）, vol.2018-SLP-120, no.14, pp.1-9. (Feb. 2018)
    <a href="http://id.nii.ac.jp/1001/00185691/">[official]</a></li>

    <li><em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``GP-DNNハイブリッドモデルに基づく統計的音声合成の検討,''</em></br>
    電子情報通信学会技術研究報告, vol.117, no.393, SP2017-67, pp.5-10. (Jan. 2018)
    <a href="http://t2r2.star.titech.ac.jp/rrws/file/CTT100758688/ATD100000413/">[PDF]</a>
    <a href="http://www.ieice.org/ken/paper/2018012001BH/">[official]</a>
    <a href="./demo/1801SP/index.html">[demo]</a>
    <a href="https://www.slideshare.net/tomokikoriyama/gpdnn">[slide]</a></li>

    <li>峯松信明, 秋田祐哉, 浅見太一, 伊藤信貴, 落合翼, <em class="author">郡山知樹</em>, 齋藤大輔, 塩田さやか, 篠崎隆宏, 鈴木雅之, 高木信二, 俵直弘, 橋本佳, 樋口卓哉, 福田隆,<br />
    <em class="title">``国際会議ICASSP2016参加報告,''</em></br>
    研究報告音声言語情報処理（SLP）, vol.2016-SLP-112, no.5, pp.1-6. (July 2016)
    <a href="http://id.nii.ac.jp/1001/00169842/">[official]</a></li>

    <li>博多屋涼, 篠崎隆宏, <em class="author">郡山知樹</em>,<br />
    <em class="title">``粒子フィルタとガウス過程回帰によるシングルチャネル音源分離,''</em></br>
    研究報告音声言語情報処理（SLP）, vol.2016-SLP-110, no.6, pp.1-6. (Jan. 2016)
    <a href="http://id.nii.ac.jp/1001/00147547/">[official]</a></li>

    <li>増子理菜, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``音声合成のためのCRF/HMMに基づく自動アクセント推定の評価,''</em></br>
    電子情報通信学会技術研究報告, vol.115, no.392, SP2015-85, pp.1-6. (Jan. 2016)
    <a href="http://www.ieice.org/ken/paper/20160114bb5i/">[official]</a></li>

    <li>岡本拓磨, 小川哲司, 落合翼, 柏木陽佑, 亀岡弘和, 木下慶介, <em class="author">郡山知樹</em>, 齋藤大輔, 篠崎隆宏, 高木信二, 滝口哲也, 太刀岡勇気, 俵直弘, 橋本佳, 藤本雅清, 松田繁樹, 三村正人, 吉岡拓也, 渡部晋治,<br />
    <em class="title">``国際会議ICASSP2015参加報告,''</em></br>
    研究報告音声言語情報処理（SLP）, vol.2015-SLP-107, no.3, pp.1-7. (July 2015)
    <a href="http://id.nii.ac.jp/1001/00142613/">[official]</a></li>

    <li><em class="author">郡山知樹</em>, 能勢 隆, 小林隆夫,<br />
    <em class="title">``ガウス過程回帰に基づく音声合成におけるハイパーパラメータ最適化の検討,''</em></br>
    電子情報通信学会技術研究報告, vol.113, no.404, SP2013-99, pp.19-24. (Jan. 2014)</li>

    <li>鈴木啓史, <em class="author">郡山知樹</em>, 能勢 隆, 篠崎隆宏, 小林隆夫,<br />
    <em class="title">``言語モデルと音響モデルを利用したアクセント境界の自動推定,''</em></br>
    電子情報通信学会技術研究報告, vol.113, no.366, SP2013-89, pp.97-102. (Dec. 2013)</li>

    <li>能勢 隆, 金本美沙, <em class="author">郡山知樹</em>, 小林隆夫,<br />
    <em class="title">``多様な歌声合成のための重回帰HSMMに基づくスタイル制御法の検討,''</em></br>
    電子情報通信学会技術研究報告, vol.112, no.422, SP2012-111, pp.79-84. (Jan. 2013)</li>

    <li>前野 悠, 能勢 隆, 小林隆夫, <em class="author">郡山知樹</em>, 井島勇祐, 中嶋秀治, 水野秀之, 吉岡 理,<br />
    <em class="title">``多様な韻律生成のための多クラス局所韻律コンテキストの検討,''</em></br>
    電子情報通信学会技術研究報告, vol.112, no.422, SP2012-112, pp.85-90. (Jan. 2013)</li>

    <li><em class="author">郡山知樹</em>, 能勢 隆, 小林隆夫,<br />
    <em class="title">``韻律イベントHMMを用いた対話音声F0生成,''</em></br>
    電子情報通信学会技術研究報告, vol.111, no.365, SP2011-98, pp.185-190. (Dec. 2011)</li>

    <li><em class="author">郡山知樹</em>, 能勢 隆, 小林隆夫,<br />
    <em class="title">``日本語話し言葉コーパスを用いた対話音声合成のためのコンテキストの評価,''</em></br>
    電子情報通信学会技術研究報告, vol.111, no.28, SP2011-27, pp.155-160. (May 2011)</li>

    <li><em class="author">郡山知樹</em>, 能勢 隆, 小林隆夫,<br />
    <em class="title">``平均声に基づく対話音声合成に関する検討,''</em></br>
    電子情報通信学会技術研究報告, vol.109, no.375, SP2009-101, pp.33-38. (Jan. 2010)</li>


</ol>
</div>

<a name="books"></a>
<h2>著書</h2>
<ol class="publication">
    <li>日本音響学会 編（分担）, <br />
    <em class="title">音響学入門ペディア</em></br>
    コロナ社, ISBN978-4-339-00895-1. (Mar. 2017)
    <a href="http://www.coronasha.co.jp/np/isbn/9784339008951/">[official]</a></li>
</ol>

  </div>

<!-- メインコンテンツ終わり -->

<!-- メニュー -->

  <div id="menu">


<div class="menulist">
   <h2>コンテンツ</h2>
<a href="#journal">論文</a>
<a href="#international_conference">国際会議</a>
<a href="#review">招待論文・解説</a>
<a href="#domestic_conference">国内大会</a>
<a href="#domestic_workshop">国内研究会</a>
<a href="#books">著書</a>
</div>



<div class="menu_free">
<h2>連絡先</h2>
<p>Email: tomoki_koriyama [at] ipc.i.u-tokyo.ac.jp</p>
<p>〒113-8656<br />
東京都文京区本郷7-3-1<br />
工学部6号館 140号室
</p>
</div>


<div class="menulist">
   <h2>リンク</h2>
<a href="http://www.sp.ipc.i.u-tokyo.ac.jp/">システム情報学専攻 第一研究室</a>
<a href="http://www.kbys.ip.titech.ac.jp/">小林・篠崎研究室</a>
</div>


  </div>

<!-- メニュー終わり -->

</div>

<!-- コンテンツ終わり -->

<!-- フッター -->

<div id="footer">
Copyright (C) 2013 Tomoki Koriyama All Rights Reserved.　design by <a href="http://tempnate.com/">tempnate</a>
</div>

<!-- フッター終わり -->

</div>

<!-- メイン終わり -->

</body>
</html>
